1:"$Sreact.fragment"
2:I[99897,["/_next/static/chunks/4eaa70fe861e9598.js","/_next/static/chunks/946bdd2e6c9b7c49.js","/_next/static/chunks/6dd6809ee42e252f.js","/_next/static/chunks/f2b800ca7ae14e96.js","/_next/static/chunks/e121db38c98deeb4.js","/_next/static/chunks/0973dd923ca2781d.js","/_next/static/chunks/b397c2fd2abb1207.js","/_next/static/chunks/11dff99839ab5ba0.js"],"MotionPreset"]
3:I[22016,["/_next/static/chunks/4eaa70fe861e9598.js","/_next/static/chunks/946bdd2e6c9b7c49.js","/_next/static/chunks/6dd6809ee42e252f.js","/_next/static/chunks/f2b800ca7ae14e96.js","/_next/static/chunks/e121db38c98deeb4.js","/_next/static/chunks/0973dd923ca2781d.js","/_next/static/chunks/b397c2fd2abb1207.js","/_next/static/chunks/11dff99839ab5ba0.js"],""]
4:I[85437,["/_next/static/chunks/4eaa70fe861e9598.js","/_next/static/chunks/946bdd2e6c9b7c49.js","/_next/static/chunks/6dd6809ee42e252f.js","/_next/static/chunks/f2b800ca7ae14e96.js","/_next/static/chunks/e121db38c98deeb4.js","/_next/static/chunks/0973dd923ca2781d.js","/_next/static/chunks/b397c2fd2abb1207.js","/_next/static/chunks/11dff99839ab5ba0.js"],"Image"]
5:I[48347,["/_next/static/chunks/4eaa70fe861e9598.js","/_next/static/chunks/946bdd2e6c9b7c49.js","/_next/static/chunks/6dd6809ee42e252f.js","/_next/static/chunks/f2b800ca7ae14e96.js","/_next/static/chunks/e121db38c98deeb4.js","/_next/static/chunks/0973dd923ca2781d.js","/_next/static/chunks/b397c2fd2abb1207.js","/_next/static/chunks/11dff99839ab5ba0.js"],"default"]
6:I[72436,["/_next/static/chunks/4eaa70fe861e9598.js","/_next/static/chunks/946bdd2e6c9b7c49.js","/_next/static/chunks/6dd6809ee42e252f.js","/_next/static/chunks/f2b800ca7ae14e96.js","/_next/static/chunks/e121db38c98deeb4.js","/_next/static/chunks/0973dd923ca2781d.js","/_next/static/chunks/b397c2fd2abb1207.js","/_next/static/chunks/11dff99839ab5ba0.js"],"Separator"]
e:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"OutletBoundary"]
f:"$Sreact.suspense"
0:{"buildId":"fgnevoCcv3TjAYBn9b4Wj","rsc":["$","$1","c",{"children":[["$","section",null,{"className":"relative","children":["$","$L2",null,{"fade":true,"blur":true,"transition":{"duration":0.5},"delay":0.1,"className":"relative overflow-hidden border-y xl:flex","children":[["$","div",null,{"className":"m-6 w-full flex-1 bg-[radial-gradient(circle_at_center,color-mix(in_oklab,var(--primary)_15%,transparent)_2px,transparent_2px)] bg-size-[18px_18px] max-xl:hidden"}],["$","div",null,{"className":"mx-auto w-full max-w-6xl flex-none space-y-8 px-4 py-8 min-[1158px]:border-x sm:px-6 sm:py-12 lg:px-8","children":[["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"down","offset":30},"transition":{"duration":0.4},"children":["$","$L3",null,{"href":"/blog","className":"text-muted-foreground hover:text-foreground inline-flex items-center gap-2 text-sm transition-colors","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left h-4 w-4","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"返回","技术博客"]}]}],["$","article",null,{"className":"mx-auto max-w-4xl","children":[["$","header",null,{"className":"mb-8 space-y-6","children":[["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"up","offset":50},"delay":0.2,"transition":{"duration":0.6},"children":["$","div",null,{"className":"relative aspect-video overflow-hidden rounded-xl","children":["$","$L4",null,{"src":"https://cdn.nlark.com/yuque/0/2020/png/1484158/1598686130909-116e16a4-e86a-46e0-93fb-ac0263257056.png","alt":"机器学习scikit-learn库的使用","fill":true,"className":"object-cover","unoptimized":true}]}]}],["$","$L2",null,{"delay":0.3,"transition":{"duration":0.5},"children":["$","h1",null,{"className":"text-2xl font-bold tracking-tight sm:text-3xl md:text-4xl","children":["$","$L5",null,{"text":"机器学习scikit-learn库的使用","delay":30,"animateBy":"words","direction":"bottom"}]}]}],["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"down","offset":30},"delay":0.4,"transition":{"duration":0.5},"children":["$","p",null,{"className":"text-muted-foreground text-lg","children":"一、机器学习的一些概念基本概念特征：一组数据的多个属性标签：人为指定特征监督学习：就像分类（离散化的标签），回归（连续性的标签）、【“有标准答案”】无监督学习：就像聚类【“无标准答案”】数据：是机器学习的命脉基本框架图二、机器学习的一些阶段/步骤sklearn相关提及官网scikit-lear..."}]}],["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"down","offset":30},"delay":0.5,"transition":{"duration":0.5},"children":["$","div",null,{"className":"text-muted-foreground flex flex-wrap items-center gap-4 text-sm","children":[["$","div",null,{"className":"flex items-center gap-1","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-calendar h-4 w-4","aria-hidden":"true","children":[["$","path","1cmpym",{"d":"M8 2v4"}],["$","path","4m81vk",{"d":"M16 2v4"}],["$","rect","1hopcy",{"width":"18","height":"18","x":"3","y":"4","rx":"2"}],["$","path","8toen8",{"d":"M3 10h18"}],"$undefined"]}],["$","span",null,{"children":"2022年7月9日"}]]}],["$","div",null,{"className":"flex items-center gap-1","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-clock h-4 w-4","aria-hidden":"true","children":[["$","path","mmk7yg",{"d":"M12 6v6l4 2"}],["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],"$undefined"]}],["$","span",null,{"children":"1.8千字"}]]}],["$","div",null,{"className":"flex items-center gap-1","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-eye h-4 w-4","aria-hidden":"true","children":[["$","path","1nclc0",{"d":"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"}],["$","circle","1v7zrd",{"cx":"12","cy":"12","r":"3"}],"$undefined"]}],["$","span",null,{"children":[11," 阅读"]}]]}],false,false]}]}],false]}],["$","$L2",null,{"delay":0.6,"fade":true,"blur":true,"transition":{"duration":0.6},"className":"-mx-4 sm:-mx-6 lg:-mx-8","children":["$","$L6",null,{}]}],["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"up","offset":50},"delay":0.7,"transition":{"duration":0.6},"children":"$L7"}],"$L8","$L9"]}]]}],"$La"]}]}],["$Lb"],"$Lc"]}],"loading":null,"isPartial":false}
d:T5efc,<!doctype html><div class="lake-content" typography="classic"><h2 id="5bee3f0f"><span class="ne-text">一、机器学习的一些概念</span></h2><h3 id="e2d6d0e3"><span class="ne-text">基本概念</span></h3><ul class="ne-ul"><li id="d2d782db5069f8dae8b6a1bff6271770"><span class="ne-text">特征：一组数据的多个属性</span></li><li id="1ae1f056eb066684a43e6d67b7844f01"><span class="ne-text">标签：人为指定特征</span></li><li id="7a50a4b66cab34d55eca1deb1c1ab1a3"><span class="ne-text">监督学习：就像分类（离散化的标签），回归（连续性的标签）、【“有标准答案”】</span></li><li id="2769fd3cae1a5e79bed5c3269bde5c65"><span class="ne-text">无监督学习：就像聚类【“无标准答案”】</span></li><li id="7581b3163cfaa24b8f99df504d81cd20"><strong><span class="ne-text">数据</span></strong><span class="ne-text">：是机器学习的命脉</span></li></ul><p id="0ceea112001075e31517062efafa3ad8" class="ne-p"><br></p><h3 id="ed38e053"><span class="ne-text">基本框架图</span></h3><p id="eb6bf04abe1d9f83c3ecca43f734d4bf" class="ne-p"><br></p><p id="250704e17a13248b5fb5b23d9d313a66" class="ne-p" style="text-align: center"><img src="https://cdn.nlark.com/yuque/0/2020/png/1484158/1598686130909-116e16a4-e86a-46e0-93fb-ac0263257056.png" width="453" id="F2NI4" class="ne-image"></p><p id="7a9cfeb28d8dc025f7e248610c39d913" class="ne-p" style="text-align: center"><img src="https://cdn.nlark.com/yuque/0/2020/png/1484158/1598686131288-431d8fe6-bf3f-4f3e-9986-9b282e9e2982.png" width="475" id="LzfkG" class="ne-image"></p><p id="73e4f1fcaf93d5eeedf210175c8ee3a9" class="ne-p"><br></p><h2 id="a72013d5"><span class="ne-text">二、机器学习的一些阶段/步骤</span></h2><p id="050e76919058cb184eb20ef48961b3b2" class="ne-p"><br></p><h3 id="cef7202b"><span class="ne-text">sklearn相关提及</span></h3><p id="1fafce44ffb6281355e9421dc94c9fc1" class="ne-p"><br></p><p id="9db7f6fb2b04cf93dcc8fa3728c6158f" class="ne-p"><a href="https://scikit-learn.org/stable/testimonials/testimonials.html" data-href="https://scikit-learn.org/stable/testimonials/testimonials.html" target="_blank" class="ne-link"><span class="ne-text">官网scikit-learn</span></a></p><p id="c843d200c3848ad05cc984f83a9d2e3f" class="ne-p"><br></p><ol class="ne-ol"><li id="9805e279fad9f4cd1b787cbb59e6a2bb"><span class="ne-text">包含聚类、分类、回归等算法<br /></span><span class="ne-text">eg：随机森林、k-means、SVM等</span></li><li id="db3038ecab25f3fc24d631311365ae13"><span class="ne-text">包含模型筛选、降维、预处理等算法</span></li><li id="54c678cfeb754645357efec91f999024"><span class="ne-text">要特别注意安装该包使用要注意的细节，具体参考上一篇博客</span></li></ol><p id="2e30cd945612807b08816b4cc33f5568" class="ne-p"><br></p><h3 id="f2bc4819"><span class="ne-text">sklearn处理机器学习的一般化sop</span></h3><p id="8022d1c4d586139cc725870d5eacff7c" class="ne-p"><br></p><ol class="ne-ol"><li id="f13ba218c28b3d269d775f7350a0850a"><strong><span class="ne-text">准备数据集</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="c5c5f4fda83ea45f98d978991c87d3a3"><span class="ne-text">数据分析</span><span class="ne-text">:（利用np.reshape()成二维(n_samples,n_features)）</span></li><li id="63a3e4964bdf56bcbc95035f6149e27c"><span class="ne-text">划分数据集：train_test_split()</span></li><li id="59ef378048ac74571cda7c44c98f3898"><span class="ne-text">特征工程：特征的提取、特征的归一化nomalization</span></li></ul></ul><ol start="2" class="ne-ol"><li id="0c68cc70de7d4b52895bb74e612b045f"><strong><span class="ne-text">选择模型</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="afc2714ef64987184b522ea6fa37a2a5"><span class="ne-text">根据不同场景选择合适的模型:</span><a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" data-href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" target="_blank" class="ne-link"><span class="ne-text">scikit-learn的模型选择路线图</span></a></li><li id="5d15b30fc6cf661cfbc37d0fb4566861"><span class="ne-text">分类、聚类、回归……</span></li></ul></ul><ol start="3" class="ne-ol"><li id="71e3de310907fb0a10e93040b9ccb56f"><span class="ne-text">在训练集上</span><strong><span class="ne-text">训练模型</span></strong><span class="ne-text">，并调整参数</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="9b9950c6e51e8c6ae10a2fbdd228def1"><span class="ne-text">经验选定参数</span></li><li id="aafbec39c5d8e67ed288bdb0265c67cc"><span class="ne-text">交叉验证确定最优的参数cross validation</span></li></ul></ul><ol start="4" class="ne-ol"><li id="13143c01f4d80cb1698eafe8386a45c2"><span class="ne-text">在测试集上</span><strong><span class="ne-text">测试模型</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="b54f8f021f312942ca8fa6b689cfae53"><span class="ne-text">predict预测、score真实值预测值评分、etc</span></li></ul></ul><ol start="5" class="ne-ol"><li id="2d1c2382fe82579fbe51e7f824f435d6"><strong><span class="ne-text">保存模型</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="b50eab253057b56bb54f3b3dc5b2ddbd"><code class="ne-code"><span class="ne-text">import pickle</span></code></li></ul></ul><p id="4552fb1bc582283e48711dcd041031d1" class="ne-p"><br></p><h3 id="88197008"><span class="ne-text">主成分分析：将特征降维</span></h3><p id="0d3292eb853d31942b5cda713773fccd" class="ne-p"><br></p><ul class="ne-ul"><li id="be0894fecc9d50b0d38969bb4c9b4641"><span class="ne-text">统计学相关知识：方差（衡量在一个维度的偏差）、协方差（衡量一个维度是否对另一个维度有影响cov（x，y））</span></li><li id="805bf986765a88e71efddbab8cffecf6"><span class="ne-text">线代相关知识：特征值、特征向量、协方差向量</span></li><li id="a4e955004f4587c2bd327f7dda04414f"><span class="ne-text">PCA</span></li></ul><p id="2d0a46eb2b25603e3431acc63be10047" class="ne-p"><br></p><p id="b8bfe4715d89bd2397f34a17fbc29673" class="ne-p"><a href="http://q5e49p23n.bkt.clouddn.com/scikit_pca.html" data-href="http://q5e49p23n.bkt.clouddn.com/scikit_pca.html" target="_blank" class="ne-link"><span class="ne-text">相关代码html页面</span></a></p><p id="14a0b4bf064d45461b9c269466566ec1" class="ne-p"><br></p><h2 id="c85531aa"><span class="ne-text">三、通过scikit-learn认识机器学习</span></h2><p id="b9f86893b1532af72bc0fa5deaf7a4c1" class="ne-p"><br></p><h3 id="c11d2053"><span class="ne-text">加载示例数据集</span></h3><p id="72b6c2ed2e671a5e099e132f46ea3a19" class="ne-p"><br></p><pre data-language="python" id="39188184" class="ne-codeblock language-python">from sklearn import datasets
iris = datasets.load_iris()#用sklearn自身配带的数据
digits = datasets.load_digits()
# C:\Users\wztli\Anaconda3\pkgs\scikit-learn-0.21.3-py37h6288b17_0\Lib\site-packages\sklearn\datasets\data
# 数据集在电脑中的位置</pre><p id="69e1a15bea11fdcf845239a8237db4c4" class="ne-p"><br></p><pre data-language="python" id="fe71e276" class="ne-codeblock language-python"># 查看数据集
# iris
print(iris.data[:5])
print(iris.data.shape)
print(iris.target_names)
print(iris.target)</pre><p id="2c82c2a79829d6250f8aae3e4415a676" class="ne-p"><br></p><pre data-language="python" id="6c1a82be" class="ne-codeblock language-python">[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]]
(150, 4)
['setosa' 'versicolor' 'virginica']
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]</pre><p id="75fb5f18a8ca61a6d2f8d213b9a93ea0" class="ne-p"><br></p><pre data-language="python" id="76a6509c" class="ne-codeblock language-python"># digits
print(digits.data)
print(digits.data.shape)
print(digits.target_names)
print(digits.target)</pre><p id="c08e4f227e41ac1048417c7eba4443a6" class="ne-p"><br></p><pre data-language="python" id="ed329957" class="ne-codeblock language-python">[[ 0.  0.  5. ...  0.  0.  0.]
 [ 0.  0.  0. ... 10.  0.  0.]
 [ 0.  0.  0. ... 16.  9.  0.]
 ...
 [ 0.  0.  1. ...  6.  0.  0.]
 [ 0.  0.  2. ... 12.  0.  0.]
 [ 0.  0. 10. ... 12.  1.  0.]]
(1797, 64)
[0 1 2 3 4 5 6 7 8 9]
[0 1 2 ... 8 9 8]</pre><p id="6bb801e7672fafcf2402ad8b2eada8b9" class="ne-p"><br></p><h3 id="2e430784"><span class="ne-text">在训练集上训练模型</span></h3><p id="ea0bd901af9a5698d87611a8431800f7" class="ne-p"><br></p><pre data-language="python" id="0093a4fb" class="ne-codeblock language-python"># 手动划分训练集、测试集 
n_test = 100 # 测试样本个数
train_X = digits.data[:-n_test, :]
train_y = digits.target[:-n_test]

test_X = digits.data[-n_test:, :]
y_true = digits.target[-n_test:]</pre><p id="4c84d82408c9a7607fdde54aab1c5fea" class="ne-p"><br></p><pre data-language="python" id="2f828cd8" class="ne-codeblock language-python"># 选择SVM模型
from sklearn import svm

svm_model = svm.SVC(gamma=0.001, C=100.)
# svm_model = svm.SVC(gamma=100., C=1.)

# 训练模型
svm_model.fit(train_X, train_y)
#训练要放入两个参数：样本的特征数据，样本的标签</pre><p id="8966759209375247b0896c8e7ec13b52" class="ne-p"><br></p><pre data-language="python" id="d425e330" class="ne-codeblock language-python">SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)</pre><p id="3143848dcca4492177329a5a5bd3dd8b" class="ne-p"><br></p><pre data-language="python" id="b0f2ef5b" class="ne-codeblock language-python"># 选择LR（逻辑回归）模型
from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression()
# 训练模型
lr_model.fit(train_X, train_y)</pre><p id="c24ae4e4bd254df0142100716c8430b4" class="ne-p"><br></p><pre data-language="python" id="268e3d8f" class="ne-codeblock language-python">C:\Users\wztli\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\wztli\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.
  &quot;this warning.&quot;, FutureWarning)





LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False)</pre><p id="b50e7f4b41f61ea572f7d7f4c695e57a" class="ne-p"><br></p><h3 id="fedce9bc"><span class="ne-text">在测试集上测试模型</span></h3><p id="4fa0e85e0eb9c3fcd97c3ac317840bbb" class="ne-p"><br></p><pre data-language="python" id="dd6817a7" class="ne-codeblock language-python">y_pred_svm = svm_model.predict(test_X)
y_pred_lr = lr_model.predict(test_X)</pre><p id="7cfc4933ab8163a87e6df6d42796f957" class="ne-p"><br></p><pre data-language="python" id="490d0d5b" class="ne-codeblock language-python"># 查看结果
# 评价指标
from sklearn.metrics import accuracy_score

#print '预测标签：', y_pred
#print '真实标签：', y_true

print('SVM结果：', accuracy_score(y_true, y_pred_svm))
print('LR结果：', accuracy_score(y_true, y_pred_lr))</pre><p id="c3283b91cc35ef6836bbf6f1e7e2b30f" class="ne-p"><br></p><pre data-language="python" id="46f01b6c" class="ne-codeblock language-python">SVM结果： 0.98
LR结果： 0.94</pre><p id="ae4787e0e9369132023f669d68bcff3a" class="ne-p"><br></p><h3 id="2368cbf8"><span class="ne-text">保存模型</span></h3><p id="711dfa9304a4069ee9c72dbaf8af9914" class="ne-p"><br></p><pre data-language="python" id="1b5ea740" class="ne-codeblock language-python">import pickle

with open('svm_model.pkl', 'wb') as f:
    pickle.dump(svm_model, f)</pre><p id="393f058aef4b4b4fce8c679b3ddeca2d" class="ne-p"><br></p><pre data-language="python" id="84f4c044" class="ne-codeblock language-python">import numpy as np

# 重新加载模型进行预测
with open('svm_model.pkl', 'rb') as f:
    model = pickle.load(f)

random_samples_index = np.random.randint(0, 1796, 5)
random_samples = digits.data[random_samples_index, :]
random_targets = digits.target[random_samples_index]

random_predict = model.predict(random_samples)

print(random_predict)
print(random_targets)</pre><p id="f22dffbb49c54ba3a3375c22a1e1780d" class="ne-p"><br></p><pre data-language="python" id="cdcf5a6d" class="ne-codeblock language-python">[2 2 1 3 8]
[2 2 1 3 8]</pre><p id="daa5b608f7016bc41e60043754db5b5b" class="ne-p"><br></p><p id="253af5b5a05a4f63bd2da5ada2ab7b42" class="ne-p"><br></p><h2 id="5ca8154b"><span class="ne-text">四、scikit-learn入门</span></h2><p id="0e97c0d59899fdd888caa6fdaf4ac7b0" class="ne-p"><br></p><h3 id="15d049a5"><span class="ne-text">准备数据集</span></h3><p id="e87a310596dcc968db1d5ce53a065989" class="ne-p"><br></p><pre data-language="python" id="0f634997" class="ne-codeblock language-python">import numpy as np
from sklearn.model_selection import train_test_split</pre><p id="677abb17e30637609cf15d18fe4548bb" class="ne-p"><br></p><pre data-language="python" id="56603efa" class="ne-codeblock language-python">X = np.random.randint(0, 100, (10, 4))
y = np.random.randint(0, 4, 10)
y.sort()

print('样本：')
print(X)
print('标签：', y)</pre><p id="543b06ac3de2b0f9c100c41a0a5c2290" class="ne-p"><br></p><pre data-language="python" id="38df60c4" class="ne-codeblock language-python">样本：
[[43 43 18 78]
 [74 24 42 37]
 [36 69 84 47]
 [70 62 77 30]
 [87 38  3 96]
 [68 67 24  7]
 [66 36 72 72]
 [12 94 87 72]
 [66  5 92  6]
 [41 59 60 91]]
标签： [0 0 0 2 2 2 2 3 3 3]</pre><p id="f5dd0524eabf3f9400602f9a46a7e5e8" class="ne-p"><br></p><pre data-language="python" id="b670cb91" class="ne-codeblock language-python"># 分割训练集、测试集
# random_state确保每次随机分割得到相同的结果
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=7) 

print('训练集：')
print(X_train)
print(y_train)

print('测试集：')
print(X_test)
print(y_test)</pre><p id="48e56a34adc66c2e5c55c3c9d74fd27f" class="ne-p"><br></p><pre data-language="python" id="78c7804e" class="ne-codeblock language-python">训练集：
[[63 56  7 42]
 [40 47 17 23]
 [41 31 26  8]
 [79 30 22 88]
 [54 85 48 54]
 [89 73 77 41]]
[0 1 1 0 1 1]
测试集：
[[ 3  0 42 86]
 [42 96 83 38]
 [33 45  8 37]
 [ 1 44 75  7]]
[1 1 0 0]</pre><p id="6770977ecd10dd5d619ab1d28996764e" class="ne-p"><br></p><pre data-language="python" id="51aba882" class="ne-codeblock language-python"># 特征归一化
from sklearn import preprocessing

x1 = np.random.randint(0, 1000, 5).reshape(5,1)
x2 = np.random.randint(0, 10, 5).reshape(5, 1)
x3 = np.random.randint(0, 100000, 5).reshape(5, 1)

X = np.concatenate([x1, x2, x3], axis=1)
print(X)</pre><p id="85bc1e247acd1d16e6b704dd5da2a813" class="ne-p"><br></p><pre data-language="python" id="e006d96b" class="ne-codeblock language-python">[[  353     4 27241]
 [  999     4 34684]
 [  911     4 78606]
 [  310     6 44593]
 [  817     9  6356]]</pre><p id="dc10186fca14068b5fe5986e09b9f92f" class="ne-p"><br></p><pre data-language="python" id="1d8e9453" class="ne-codeblock language-python">print(preprocessing.scale(X))</pre><p id="430c7a343ef9d25ac1541ef957180558" class="ne-p"><br></p><pre data-language="python" id="1190a7c9" class="ne-codeblock language-python">[[-1.12443958 -0.71443451 -0.46550183]
 [ 1.11060033 -0.71443451 -0.15209341]
 [ 0.80613669 -0.71443451  1.69736578]
 [-1.27321159  0.30618622  0.26515287]
 [ 0.48091416  1.83711731 -1.34492342]]</pre><p id="204053c1a3a2c98fa486d34865ead442" class="ne-p"><br></p><pre data-language="python" id="e44c6095" class="ne-codeblock language-python"># 生成分类数据进行验证scale的必要性
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
%matplotlib inline

X, y = make_classification(n_samples=300, n_features=2, n_redundant=0, n_informative=2, 
                           random_state=25, n_clusters_per_class=1, scale=100)

plt.scatter(X[:,0], X[:,1], c=y)
plt.show()</pre><p id="df434115680152f8ffa701ec8283165a" class="ne-p"><br></p><p id="584acfcd9658a334d1253064bd0c0394" class="ne-p" style="text-align: center"><img src="https://cdn.nlark.com/yuque/0/2020/png/1484158/1598686130636-3a18d8f2-51cb-4b04-8a0f-a40cf1d0b9b6.png" width="384" id="BKtnM" class="ne-image"></p><p id="15c96f58169f6c9d950cfa7e385d4eb4" class="ne-p"><br></p><pre data-language="python" id="9f7881f7" class="ne-codeblock language-python">from sklearn import svm

# 注释掉以下这句表示不进行特征归一化     
X = preprocessing.scale(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=7) 
svm_classifier = svm.SVC()
svm_classifier.fit(X_train, y_train)
svm_classifier.score(X_test, y_test)</pre><p id="cd9793129aa04ea0d6f6c35636421e24" class="ne-p"><br></p><pre data-language="python" id="b57502f9" class="ne-codeblock language-python">C:\Users\wztli\Anaconda3\lib\site-packages\sklearn\svm\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
  &quot;avoid this warning.&quot;, FutureWarning)





0.25</pre><p id="64d401b7c2e36d9ed5539dd517136770" class="ne-p"><br></p><h3 id="a162534b"><span class="ne-text">训练模型</span></h3><p id="dd2ce1398f6117ba5ca42c6d622ed617" class="ne-p"><br></p><pre data-language="python" id="04ca9595" class="ne-codeblock language-python"># 回归模型
from sklearn import datasets

boston_data = datasets.load_boston()
X = boston_data.data
y = boston_data.target

print('样本：')
print(X[:5, :])
print('标签：')
print(y[:5])</pre><p id="a08b7063785f4dbcc5a662aaf1925f11" class="ne-p"><br></p><pre data-language="python" id="7dfbd578" class="ne-codeblock language-python">样本：
[[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00
  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02
  4.9800e+00]
 [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00
  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02
  9.1400e+00]
 [2.7290e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 7.1850e+00
  6.1100e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9283e+02
  4.0300e+00]
 [3.2370e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 6.9980e+00
  4.5800e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9463e+02
  2.9400e+00]
 [6.9050e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 7.1470e+00
  5.4200e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9690e+02
  5.3300e+00]]
标签：
[24.  21.6 34.7 33.4 36.2]</pre><p id="98101aaad54eaf5ee059928edd05c11c" class="ne-p"><br></p><pre data-language="python" id="a90a7a03" class="ne-codeblock language-python"># 选择线性回顾模型
from sklearn.linear_model import LinearRegression

lr_model = LinearRegression()</pre><p id="c668aa03a5ba249b3a649e72af7cbe86" class="ne-p"><br></p><pre data-language="python" id="0b1239d4" class="ne-codeblock language-python">from sklearn.model_selection import train_test_split

# 分割训练集、测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=7)</pre><p id="139269d9c14d92afa60662bf15cf4528" class="ne-p"><br></p><pre data-language="python" id="96137b34" class="ne-codeblock language-python"># 训练模型
lr_model.fit(X_train, y_train)</pre><p id="4fc615f05f90aba2d7cdc715364d250f" class="ne-p"><br></p><pre data-language="python" id="2321fe84" class="ne-codeblock language-python">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)</pre><p id="251fef8ddb74a2c95c6fa6932b69b2d8" class="ne-p"><br></p><pre data-language="python" id="d29dc43a" class="ne-codeblock language-python"># 返回参数
lr_model.get_params()</pre><p id="eb617c84c76be9c4eec131f70e997ad9" class="ne-p"><br></p><pre data-language="python" id="5fdd5527" class="ne-codeblock language-python">{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}</pre><p id="c42dc688472c0e2324aa698f31da80f7" class="ne-p"><br></p><pre data-language="python" id="f792d5ad" class="ne-codeblock language-python">lr_model.score(X_train, y_train)</pre><p id="2c7b205b5802cd82901cee3aabb5b120" class="ne-p"><br></p><pre data-language="python" id="undefined0.7598132492351114" class="ne-codeblock language-python">0.7598132492351114</pre><p id="03dd00659a65b34b00137f7b4f13a21c" class="ne-p"><br></p><pre data-language="python" id="815e97f6" class="ne-codeblock language-python">lr_model.score(X_test, y_test)</pre><p id="63ff02db23bd9fdb0ab22157b50127fd" class="ne-p"><br></p><pre data-language="python" id="undefined0.6693852753319398" class="ne-codeblock language-python">0.6693852753319398</pre><p id="d11e0df1150b9cc415330ed1897dc791" class="ne-p"><br></p><h3 id="95c01146"><span class="ne-text">交叉验证</span></h3><p id="e7d50bcfa04456167bf498f3906f048b" class="ne-p"><br></p><pre data-language="python" id="338e8c28" class="ne-codeblock language-python">from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
%matplotlib inline

iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=10) 

k_range = range(1, 31)
cv_scores = []
for n in k_range:
    knn = KNeighborsClassifier(n)
    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy') # 分类问题使用
    #scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='neg_mean_squared_error') # 回归问题使用
    cv_scores.append(scores.mean())
    
plt.plot(k_range, cv_scores)
plt.xlabel('K')
plt.ylabel('Accuracy')
plt.show()</pre><p id="a0cded2f71f7aa3fa90d3eaadfecd803" class="ne-p"><br></p><p id="2c0277bb65360b70642be04d029190f5" class="ne-p" style="text-align: center"><img src="https://cdn.nlark.com/yuque/0/2020/png/1484158/1598686130618-179a3dfa-9ffd-4f45-9cc2-d6f63e1ad2b9.png" width="392" id="uSgI0" class="ne-image"></p><p id="493f3ee2cd36e50d58098a4754934f4e" class="ne-p"><br></p><pre data-language="python" id="d9f66869" class="ne-codeblock language-python"># 选择最优的K
best_knn = KNeighborsClassifier(n_neighbors=5)
best_knn.fit(X_train, y_train)
print(best_knn.score(X_test, y_test))
print(best_knn.predict(X_test))</pre><p id="53630747d5d6a54a8f8691293beb276a" class="ne-p"><br></p><pre data-language="python" id="140f5587" class="ne-codeblock language-python">0.96
[1 2 0 1 0 1 2 1 0 1 1 2 1 0 0 2 1 0 0 0 2 2 2 0 1 0 1 1 1 2 1 1 2 2 2 0 2
 2 2 2 0 0 1 0 1 0 1 2 2 2]</pre><p id="1dade961417cd6d7c846d50bdce2ee94" class="ne-p"><br></p><span id="python-1"></span><p id="91ae545daa1b2a4b77f487c8256edd44" class="ne-p"><br></p><h2 id="tmokZ"><span class="ne-text">参考</span></h2><ul class="ne-ul"><li id="658d75dd41d71405e20edf15c803b74d"><a href="https://github.com/wztlink1013/scikit-learn" data-href="https://github.com/wztlink1013/scikit-learn" target="_blank" class="ne-link"><span class="ne-text">scikit-learn中文文档github</span></a><span class="ne-text">文中链接为英文文档</span></li><li id="15a722080e24c81b2e413a8594541477"><a href="https://blog.csdn.net/Little_Fire/article/details/81062447" data-href="https://blog.csdn.net/Little_Fire/article/details/81062447" target="_blank" class="ne-link"><span class="ne-text">解释iris数据集</span></a></li></ul></div>7:["$","div",null,{"className":"prose prose-neutral dark:prose-invert mt-8 max-w-none","dangerouslySetInnerHTML":{"__html":"$d"}}]
8:["$","$L2",null,{"delay":0.8,"fade":true,"blur":true,"transition":{"duration":0.6},"className":"-mx-4 mt-12 sm:-mx-6 lg:-mx-8","children":["$","$L6",null,{}]}]
9:["$","$L2",null,{"fade":true,"blur":true,"slide":{"direction":"up","offset":30},"delay":0.9,"transition":{"duration":0.5},"children":["$","nav",null,{"className":"mt-8 grid gap-4 md:grid-cols-2","children":[["$","$L3",null,{"href":"/blog/esofty","className":"hover:bg-muted group flex flex-col rounded-lg border p-4 transition-colors","children":[["$","span",null,{"className":"text-muted-foreground mb-2 text-sm","children":"上一篇"}],["$","span",null,{"className":"group-hover:text-primary line-clamp-2 font-medium transition-colors","children":"基础知识"}]]}],["$","$L3",null,{"href":"/blog/apohu8","className":"hover:bg-muted group flex flex-col rounded-lg border p-4 text-right transition-colors md:text-right","children":[["$","span",null,{"className":"text-muted-foreground mb-2 text-sm","children":"下一篇"}],["$","span",null,{"className":"group-hover:text-primary line-clamp-2 font-medium transition-colors","children":"ANN神经网络"}]]}]]}]}]
a:["$","div",null,{"className":"m-6 w-full flex-1 bg-[radial-gradient(circle_at_center,color-mix(in_oklab,var(--primary)_15%,transparent)_2px,transparent_2px)] bg-size-[18px_18px] max-xl:hidden"}]
b:["$","script","script-0",{"src":"/_next/static/chunks/11dff99839ab5ba0.js","async":true}]
c:["$","$Le",null,{"children":["$","$f",null,{"name":"Next.MetadataOutlet","children":"$@10"}]}]
10:null
